# Memory Keeper - Complete Project Summary for ChatGPT Planning

## ðŸ“‹ Use This Prompt with ChatGPT

Copy the entire content below and use it as a prompt with ChatGPT for planning, architecture decisions, or feature development.

---

# Memory Keeper - Full Project Context

## ðŸŽ¯ Project Overview

**Memory Keeper** is a Next.js web application designed to help elderly people (60+ years old) preserve family memories through photos. The app uses AI to have natural conversations that extract stories, which are then synthesized into narratives and eventually animated videos.

**Tech Stack**: Next.js 16.1.1, React 19.2.3, TypeScript, Tailwind CSS, Google Gemini API, face-api.js

**Current Branch**: `story-veo` (for story generation and VEO 3 API work)

---

## âœ… What's Been Implemented

### **1. Photo Analysis System**
- âœ… Gemini Vision API integration for photo analysis
- âœ… Extracts: people, setting, era, mood, visual anchors
- âœ… Generates opening observations and first questions
- âœ… API Route: `/api/analyze-photo`

### **2. Face Recognition System**
- âœ… Client-side face detection using face-api.js
- âœ… 128-dim face embeddings for matching
- âœ… Face matching across photos (Euclidean distance, threshold 0.45)
- âœ… Memory bank storage (localStorage) for known faces
- âœ… Visual face boxes with names on photos
- âœ… Face naming and relationship tracking
- âœ… Face recognition models loaded from `/public/models/`

### **3. AI Conversation System**
- âœ… Context-aware conversations with Gemini
- âœ… Proactive questioning (AI asks follow-up questions)
- âœ… Automatic extraction of names, places, dates
- âœ… Memory dossier tracking (names, places, dates)
- âœ… Conversation history management
- âœ… API Route: `/api/chat`
- âœ… System prompts in `src/lib/prompts.ts`

### **4. Story Generation**
- âœ… Story synthesis from conversations
- âœ… Pure narration format (first-person, no AI references)
- âœ… 200-500 word narratives
- âœ… Photo-conversation correlation
- âœ… API Route: `/api/generate-story`
- âœ… Story generation from Live API conversations

### **5. Gemini Live API Integration**
- âœ… Real-time WebSocket connection to Gemini Live API
- âœ… Audio responses (voice output)
- âœ… Video frame streaming (camera feed)
- âœ… Microphone input (voice input)
- âœ… Photo detection and capture during conversation
- âœ… Conversation session tracking
- âœ… Message storage with photo associations
- âœ… Live mode UI component (`LiveMode.tsx`)

### **6. Photo Modes**
- âœ… **Photo Mode**: Upload and analyze static photos
- âœ… **Live Mode**: Real-time camera conversation
- âœ… Photo scanning and detection
- âœ… Multiple photo support in sessions

### **7. Data Storage**
- âœ… Conversation sessions (localStorage)
- âœ… Live conversation messages with timestamps
- âœ… Photo-to-message associations
- âœ… Memory bank (characters, faces, stories)
- âœ… Storage utilities in `src/lib/storage/conversation-storage.ts`

### **8. UI/UX**
- âœ… Playground interface for testing
- âœ… Split-screen conversation view
- âœ… Face detection panels
- âœ… Story preview and editing
- âœ… Toast notifications
- âœ… Loading states and error handling

---

## ðŸš§ What's Planned / In Progress

### **1. VEO 3 API Integration** (High Priority)
- â³ Video generation from photos + narration
- â³ Currently mocked in `/api/generate-video`
- â³ Waiting for VEO 3 API access
- â³ Will animate photos with story narration

### **2. PostgreSQL Vector Database** (High Priority)
- â³ Migrate face recognition from localStorage to PostgreSQL
- â³ Use pgvector extension for 128-dim face embeddings
- â³ Vector similarity search for face matching
- â³ Multi-user support
- â³ Persistent storage across devices
- ðŸ“„ Plan: `docs/POSTGRES_VECTOR_DATABASE.md`

### **3. Location Agent** (Medium Priority)
- â³ Geocoding places mentioned in conversation
- â³ Distance calculations between places
- â³ Location information and context
- â³ Integration with Live API
- ðŸ“„ Plan: `docs/LOCATION_AGENT_PLAN.md`

### **4. Story Album/Archive**
- â³ View all generated stories
- â³ Filter by person, date, place
- â³ Story detail pages
- â³ Related stories suggestions

### **5. Additional AI Agents** (Future)
- Timeline Agent (organize by date)
- Relationship Agent (family tree)
- Emotion Agent (sentiment analysis)
- Memory Connection Agent (link related memories)
- ðŸ“„ List: `docs/AI_AGENTS_FOR_LIVE_CHAT.md`

### **6. Frontend Redesign**
- â³ Figma designs based on user workflow
- â³ Mobile-responsive layouts
- â³ Improved accessibility
- ðŸ“„ Workflow: `docs/USER_WORKFLOW_FIGMA.md`

---

## ðŸ—ï¸ Architecture

### **Client-Side**
- React components (`src/app/page.tsx`, `src/app/playground/`)
- Face detection (face-api.js, client-side only)
- Memory bank (localStorage)
- Live API WebSocket client (`src/lib/gemini-live.ts`)

### **Server-Side**
- Next.js API Routes (`src/app/api/*`)
- Gemini API integration (`src/lib/gemini.ts`)
- API keys stored in `.env.local` (server-side only)

### **Data Flow**
```
User â†’ Client Component â†’ API Route â†’ Gemini API â†’ Response
```

### **Key Files**
- `src/lib/gemini.ts` - Gemini API wrapper
- `src/lib/gemini-live.ts` - Live API WebSocket client
- `src/lib/prompts.ts` - AI prompt templates
- `src/lib/face-service.ts` - Face detection/recognition
- `src/lib/memory-bank.ts` - LocalStorage persistence
- `src/lib/storage/conversation-storage.ts` - Conversation storage

---

## ðŸ” Security Architecture

- âœ… API keys are SERVER-SIDE ONLY
- âœ… Never exposed to client
- âœ… All Gemini calls through API routes
- âœ… Face detection is client-side (no server needed)

---

## ðŸ“Š Current Features

### **Photo Mode Flow**
1. Upload photo â†’ Face detection â†’ Name faces â†’ Start conversation
2. AI analyzes photo â†’ Asks questions â†’ User responds
3. Extract names/places/dates â†’ Generate story â†’ Preview â†’ Create video

### **Live Mode Flow**
1. Connect to Live API â†’ Start camera â†’ Show photos
2. Real-time conversation (voice + text)
3. Auto-capture photos â†’ Build conversation â†’ Generate story

### **Story Generation**
- Input: Conversation messages + associated photos
- Process: Gemini synthesizes pure narration
- Output: First-person narrative (200-500 words)
- Format: No AI references, just the story

---

## ðŸŽ¯ Key Requirements

### **User Experience**
- Simple, intuitive interface (elderly-friendly)
- Large buttons, clear labels
- Voice input support
- Natural conversation flow

### **Technical**
- TypeScript for type safety
- Server-side API key security
- Client-side face detection
- Real-time Live API integration

### **Story Quality**
- Pure narration (not conversation transcript)
- First-person perspective
- Emotional depth
- Complete stories (who, what, when, where, why)

---

## ðŸš€ Next Steps (Priority Order)

1. **Complete Location Agent** (3-4 hours)
   - Implement geocoding tools
   - Integrate with Live API
   - Test with real conversations

2. **PostgreSQL Migration** (4-6 hours)
   - Set up PostgreSQL with pgvector
   - Create database schema
   - Migrate face recognition
   - Update API routes

3. **VEO 3 Integration** (When API available)
   - Replace mocked video generation
   - Implement actual video creation
   - Test with generated stories

4. **Story Album** (2-3 hours)
   - Create album view
   - Story detail pages
   - Filtering and search

5. **Frontend Redesign** (Ongoing)
   - Implement Figma designs
   - Improve mobile experience
   - Enhance accessibility

---

## ðŸ“ Project Structure

```
gemini3hackathon/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/              # API routes (server-side)
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze-photo/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”œâ”€â”€ generate-story/
â”‚   â”‚   â”‚   â”œâ”€â”€ generate-video/ (mocked)
â”‚   â”‚   â”‚   â”œâ”€â”€ live/
â”‚   â”‚   â”‚   â”œâ”€â”€ live-token/
â”‚   â”‚   â”‚   â””â”€â”€ synthesize-story/
â”‚   â”‚   â”œâ”€â”€ playground/       # Testing interface
â”‚   â”‚   â””â”€â”€ (main)/           # Main app routes
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ gemini.ts         # Gemini API wrapper
â”‚       â”œâ”€â”€ gemini-live.ts    # Live API client
â”‚       â”œâ”€â”€ prompts.ts        # AI prompts
â”‚       â”œâ”€â”€ face-service.ts   # Face detection
â”‚       â”œâ”€â”€ memory-bank.ts    # LocalStorage
â”‚       â””â”€â”€ storage/          # Conversation storage
â”œâ”€â”€ docs/                     # Documentation
â”œâ”€â”€ public/
â”‚   â””â”€â”€ models/               # face-api.js models
â””â”€â”€ .env.local                # API keys (not in git)
```

---

## ðŸ”§ Development Guidelines

### **Adding New Features**
1. API Routes: Create in `src/app/api/[name]/route.ts`
2. Client Features: Add to components, call API routes
3. Types: Add to `src/lib/types.ts`
4. Prompts: Add to `src/lib/prompts.ts`

### **Code Patterns**
- Server-side: Use `process.env.GEMINI_API_KEY`
- Client-side: Make HTTP requests to `/api/*` routes
- Never expose API keys to client
- Use TypeScript for type safety

---

## ðŸŽ¨ Design Principles

- **Simplicity First**: Large buttons, minimal text, clear actions
- **Warm & Personal**: Nostalgic design, friendly tone
- **Accessibility**: High contrast, large touch targets, voice support
- **Progressive Disclosure**: Don't overwhelm, reveal features as needed

---

## ðŸ“š Documentation Files

- `PROJECT_CONTEXT.md` - Project overview
- `SYSTEM_ARCHITECTURE.md` - Technical architecture
- `STORY_GENERATION_PLAN.md` - Story generation details
- `USER_WORKFLOW_FIGMA.md` - UI/UX workflows
- `POSTGRES_VECTOR_DATABASE.md` - Database migration plan
- `LOCATION_AGENT_PLAN.md` - Location agent implementation
- `AI_AGENTS_GUIDE.md` - How AI agents work
- `AI_AGENTS_FOR_LIVE_CHAT.md` - Recommended agents

---

## âš ï¸ Important Notes

1. **API Keys**: Never commit `.env.local`, always server-side only
2. **Face Detection**: Client-side only (face-api.js in browser)
3. **Memory Bank**: Currently localStorage, migrating to PostgreSQL
4. **Live API**: WebSocket connection, requires auth token from server
5. **Story Format**: Pure narration, first-person, no AI references

---

## ðŸŽ¯ Current Focus

**Active Development**:
- Story generation improvements (pure narration format)
- Proactive questioning in Live API
- Location agent planning

**Waiting On**:
- VEO 3 API access for video generation
- PostgreSQL setup for vector database

**Next Sprint**:
- Location agent implementation
- PostgreSQL migration
- Story album UI

---

## ðŸ’¡ Key Insights

1. **Hybrid Approach Works**: Live API for conversation + background tools for enhancement
2. **Proactive AI**: System instructions make AI ask questions automatically
3. **Pure Narrations**: Stories should read like memories, not conversations
4. **Face Recognition**: Client-side works well, but PostgreSQL will scale better
5. **Agent Pattern**: Multiple specialized agents > one complex agent

---

Use this context to help plan features, make architecture decisions, or understand the codebase. The project is actively developed with a focus on making memory preservation easy and meaningful for elderly users.
